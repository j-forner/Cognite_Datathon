{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b6e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc9f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a735221",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlI = 'https://www.ndbc.noaa.gov/data/realtime2/KIKT.txt'\n",
    "urlB = 'https://www.ndbc.noaa.gov/data/realtime2/KBQX.txt'\n",
    "urlM = 'https://www.ndbc.noaa.gov/data/realtime2/KMIS.txt'\n",
    "\n",
    "kikt = pd.read_csv(urlI, skiprows=[1], sep='\\s+')\n",
    "kapt = pd.read_csv(urlB, skiprows=[1], sep='\\s+')\n",
    "kmis = pd.read_csv(urlM, skiprows=[1], sep='\\s+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00cdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df):\n",
    "    df = df.rename(columns={\"#YY\": \"YR\"})\n",
    "    df['datetime'] = pd.to_datetime(df.YR.astype(str) + '-' + df.MM.astype(str) + '-' + df.DD.astype(str) \\\n",
    "                         + ' ' + df.hh.astype(str) + ':' + df.mm.astype(str))\n",
    "    newdf = df[['datetime', 'WDIR', 'WSPD', 'GST', 'ATMP', 'DEWP', 'VIS']].sort_values(by=['datetime'])\n",
    "    return newdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing all the dataframes \n",
    "kikt = preproc_data(kikt)\n",
    "kapt = preproc_data(kapt)\n",
    "kmis = preproc_data(kmis)\n",
    "\n",
    "units = np.array(['datetime', 'degT', 'm/s', 'm/s', 'degC', 'degC', 'nmi'])  #units for the remaining columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfefc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"WDIR\"\n",
    "df = kikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdd3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to interpolate where columns have MM\n",
    "def interp_MM(df, column):\n",
    "    dt = df['datetime'].to_numpy().astype(float)\n",
    "    dt = (dt - np.min(dt))/(np.max(dt)-np.min(dt))\n",
    "\n",
    "    x = dt[df[column] == 'MM']\n",
    "    xp = dt[df[column] != 'MM']\n",
    "    yp = df.loc[df[column]!= 'MM', column].to_numpy().astype(float)\n",
    "\n",
    "    testing = np.interp(x, xp, yp) \n",
    "    \n",
    "    df.loc[(df[column] == 'MM'), column] =  testing\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe86d016-fdac-4254-8993-1a63a7a10183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in kikt.columns[1:]:\n",
    "    kikt = interp_MM(kikt, i)\n",
    "    kapt = interp_MM(kapt, i)\n",
    "    kmis = interp_MM(kmis, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630302a9-7eef-4964-91c9-399473e391a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>WDIR</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>GST</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>VIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>2021-12-15 00:15:00</td>\n",
       "      <td>130</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>2021-12-15 00:35:00</td>\n",
       "      <td>130</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>2021-12-15 00:55:00</td>\n",
       "      <td>130</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>2021-12-15 01:15:00</td>\n",
       "      <td>130</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>2021-12-15 01:35:00</td>\n",
       "      <td>130</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-29 14:35:00</td>\n",
       "      <td>330</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-29 17:15:00</td>\n",
       "      <td>330</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-29 17:35:00</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-29 17:55:00</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-29 18:05:00</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime WDIR WSPD  GST ATMP DEWP  VIS\n",
       "3247 2021-12-15 00:15:00  130  5.7  6.7   23   22  5.2\n",
       "3246 2021-12-15 00:35:00  130  5.7  6.7   23   22  5.2\n",
       "3245 2021-12-15 00:55:00  130  5.7  6.7   23   22  4.3\n",
       "3244 2021-12-15 01:15:00  130  5.7  6.7   23   22  5.2\n",
       "3243 2021-12-15 01:35:00  130  5.7  6.7   23   22  5.2\n",
       "...                  ...  ...  ...  ...  ...  ...  ...\n",
       "4    2022-01-29 14:35:00  330  3.1  7.7   12    3  8.7\n",
       "3    2022-01-29 17:15:00  330  2.1  7.7   12    2  8.7\n",
       "2    2022-01-29 17:35:00  330    0  7.7   13    2  8.7\n",
       "1    2022-01-29 17:55:00  330    0  7.7   13    1  8.7\n",
       "0    2022-01-29 18:05:00  330    0  7.7   14    2  8.7\n",
       "\n",
       "[3248 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d5dac-0b97-4cb6-9179-7912d532ab13",
   "metadata": {},
   "source": [
    "### Reference: https://keras.io/examples/timeseries/timeseries_weather_forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2ee4898-5bb7-4b80-b3fe-8aa2f053db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.6\n",
    "train_split = int(split_fraction * int(kapt.shape[0]))\n",
    "step = 1\n",
    "\n",
    "past = 24*3*3\n",
    "future = 72*3\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fe00d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0.796777</td>\n",
       "      <td>-1.009870</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>180.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0.796777</td>\n",
       "      <td>-1.009870</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>190.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0.796777</td>\n",
       "      <td>-1.216317</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0.931033</td>\n",
       "      <td>-1.216317</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>0.957970</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>1.226395</td>\n",
       "      <td>-1.216317</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>-1.136501</td>\n",
       "      <td>-1.629209</td>\n",
       "      <td>-1.892076</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>-1.136501</td>\n",
       "      <td>-1.629209</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>-1.136501</td>\n",
       "      <td>-1.422763</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>-1.136501</td>\n",
       "      <td>-1.422763</td>\n",
       "      <td>-2.180218</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>-1.136501</td>\n",
       "      <td>-1.216317</td>\n",
       "      <td>-2.036147</td>\n",
       "      <td>1.332051</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3      4    5\n",
       "1948  0.796777 -1.009870 -2.036147  1.332051  180.0  6.2\n",
       "1949  0.796777 -1.009870 -2.036147  1.332051  190.0  6.2\n",
       "1950  0.796777 -1.216317 -2.036147  1.332051  190.0  5.7\n",
       "1951  0.931033 -1.216317 -2.036147  0.957970  190.0  5.7\n",
       "1952  1.226395 -1.216317 -2.036147  1.332051  190.0  4.6\n",
       "...        ...       ...       ...       ...    ...  ...\n",
       "3243 -1.136501 -1.629209 -1.892076  1.332051  130.0  5.7\n",
       "3244 -1.136501 -1.629209 -2.036147  1.332051  130.0  5.7\n",
       "3245 -1.136501 -1.422763 -2.036147  1.332051  130.0  5.7\n",
       "3246 -1.136501 -1.422763 -2.180218  1.332051  130.0  5.7\n",
       "3247 -1.136501 -1.216317 -2.036147  1.332051  130.0  5.7\n",
       "\n",
       "[1300 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kapt.head()\n",
    "kapt_key = ['datetime']\n",
    "kapt_features = ['GST', 'ATMP', 'DEWP', 'VIS']\n",
    "kapt_target = ['WDIR', 'WSPD']\n",
    "\n",
    "features = kapt[kapt_features].astype(float)\n",
    "target = kapt[kapt_target].astype(float)\n",
    "features.index = kapt[kapt_key]\n",
    "\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "features[4] = target['WDIR']\n",
    "features[5] = target['WSPD'] \n",
    "\n",
    "train_data = features.loc[0 : train_split - 1]\n",
    "val_data = features.loc[train_split:]\n",
    "\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b1766b-aa9c-4e77-a28f-95980f9c0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(4)]].values\n",
    "y_train = train_data.iloc[start:end][[4, 5]]\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd850a1d-b736-420f-93f1-083af6f0b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aaaeaf0-2147-43cf-ae9a-8d6f864a05ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 216, 4)\n",
      "Target shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "x_end = len(val_data) - past - future\n",
    "\n",
    "label_start = train_split + past + future\n",
    "\n",
    "x_val = val_data.iloc[:x_end][[i for i in range(4)]].values\n",
    "y_val = features.iloc[label_start:][[4, 5]]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df14d6df-8861-4e43-ad33-31c8b7eecbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 216, 4)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               68096     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 68,354\n",
      "Trainable params: 68,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = keras.layers.LSTM(128)(inputs)\n",
    "outputs = keras.layers.Dense(2)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dca9c452-c13e-4d9b-bc89-d372021b22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 7s 118ms/step - loss: 41.8164 - val_loss: 7.4687\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.46871, saving model to cognite_model.h5\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 14.1736 - val_loss: 5.8417\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.46871 to 5.84175, saving model to cognite_model.h5\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 5s 106ms/step - loss: 13.1979 - val_loss: 5.8362\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.84175 to 5.83619, saving model to cognite_model.h5\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 13.1449 - val_loss: 5.8156\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.83619 to 5.81563, saving model to cognite_model.h5\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 13.0922 - val_loss: 5.7874\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.81563 to 5.78742, saving model to cognite_model.h5\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 13.0581 - val_loss: 5.7618\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.78742 to 5.76181, saving model to cognite_model.h5\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 13.0199 - val_loss: 5.7301\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.76181 to 5.73008, saving model to cognite_model.h5\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 5s 109ms/step - loss: 12.9901 - val_loss: 5.6996\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.73008 to 5.69958, saving model to cognite_model.h5\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.9560 - val_loss: 5.6626\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.69958 to 5.66260, saving model to cognite_model.h5\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 12.9277 - val_loss: 5.6288\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.66260 to 5.62878, saving model to cognite_model.h5\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 6s 123ms/step - loss: 12.8926 - val_loss: 5.5863\n",
      "\n",
      "Epoch 00011: val_loss improved from 5.62878 to 5.58631, saving model to cognite_model.h5\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 12.8622 - val_loss: 5.5495\n",
      "\n",
      "Epoch 00012: val_loss improved from 5.58631 to 5.54951, saving model to cognite_model.h5\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.8260 - val_loss: 5.4990\n",
      "\n",
      "Epoch 00013: val_loss improved from 5.54951 to 5.49903, saving model to cognite_model.h5\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 12.7897 - val_loss: 5.4674\n",
      "\n",
      "Epoch 00014: val_loss improved from 5.49903 to 5.46739, saving model to cognite_model.h5\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.7568 - val_loss: 5.4127\n",
      "\n",
      "Epoch 00015: val_loss improved from 5.46739 to 5.41271, saving model to cognite_model.h5\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 12.7310 - val_loss: 5.4097\n",
      "\n",
      "Epoch 00016: val_loss improved from 5.41271 to 5.40967, saving model to cognite_model.h5\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 6s 125ms/step - loss: 12.6739 - val_loss: 5.3561\n",
      "\n",
      "Epoch 00017: val_loss improved from 5.40967 to 5.35612, saving model to cognite_model.h5\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 12.6056 - val_loss: 5.3375\n",
      "\n",
      "Epoch 00018: val_loss improved from 5.35612 to 5.33750, saving model to cognite_model.h5\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 12.5658 - val_loss: 5.2415\n",
      "\n",
      "Epoch 00019: val_loss improved from 5.33750 to 5.24148, saving model to cognite_model.h5\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.5323 - val_loss: 5.2366\n",
      "\n",
      "Epoch 00020: val_loss improved from 5.24148 to 5.23658, saving model to cognite_model.h5\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 12.4720 - val_loss: 5.2436\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.23658\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.4096 - val_loss: 5.2034\n",
      "\n",
      "Epoch 00022: val_loss improved from 5.23658 to 5.20341, saving model to cognite_model.h5\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.3456 - val_loss: 5.2440\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.20341\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 12.3319 - val_loss: 5.2535\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.20341\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 5s 108ms/step - loss: 12.1903 - val_loss: 5.3071\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.20341\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.4128 - val_loss: 5.3103\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.20341\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 12.4001 - val_loss: 5.3016\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.20341\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 11.8623 - val_loss: 5.5119\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.20341\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 11.7542 - val_loss: 5.5916\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.20341\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 5s 111ms/step - loss: 11.7053 - val_loss: 5.6052\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.20341\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 11.6294 - val_loss: 5.5766\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.20341\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 11.5788 - val_loss: 5.5876\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.20341\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 11.2453 - val_loss: 5.7110\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.20341\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 5s 110ms/step - loss: 11.1660 - val_loss: 5.7703\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.20341\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 11.0921 - val_loss: 5.7922\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.20341\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 11.0808 - val_loss: 5.8279\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.20341\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 10.9763 - val_loss: 5.8351\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.20341\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 5s 112ms/step - loss: 10.8420 - val_loss: 5.8906\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.20341\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 10.7472 - val_loss: 5.9663\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.20341\n",
      "Epoch 40/100\n",
      "19/48 [==========>...................] - ETA: 2s - loss: 11.4569"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1052eeb96125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                               patience=5, min_lr=0.00001)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/envs/myenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_checkpoint = \"cognite_model.h5\"\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor=0.5,\n",
    "                                                 patience=5, \n",
    "                                                 min_lr=0.00001, \n",
    "                                                 verbose = 1)\n",
    "\n",
    "history = model.fit(dataset_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=dataset_val,\n",
    "                    callbacks=[modelckpt_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77c0d0a6-916e-42ad-b0dd-ff179e55483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8X0lEQVR4nO3de5zM9ffA8ddxqXW/l+zyXXLL/bIoIkpJFPpRqa9LopJKUZIupNv321eFokJFN5JKSqVSonRxSUTIZWUl17Bu5fL+/XE+y1i77M7u7Gdm5zwfj3mY+cxnZs4M5sz7fd4Xcc5hjDHGBCOP3wEYY4yJXJZEjDHGBM2SiDHGmKBZEjHGGBM0SyLGGGOCZknEGGNM0CyJmLAgIp+ISI/sPtdPIpIoIq1D8LxzRKS3d/0GEfksI+cG8ToVRGSviOQNNlaT+1kSMUHzvmBSLkdF5EDA7Rsy81zOubbOuUnZfW44EpHBIjI3jeOlReQfEamV0edyzr3pnLssm+I6Iek55353zhV2zh3JjudP9VpORCpn9/OanGdJxATN+4Ip7JwrDPwOXBlw7M2U80Qkn39RhqU3gKYiUjHV8euAZc65X3yIyZigWBIx2U5EWopIkojcJyJ/Aq+KSAkR+UhEtonIX971uIDHBHbR9BSRb0RkhHfuehFpG+S5FUVkrogki8gXIjJGRN5IJ+6MxPioiHzrPd9nIlI64P5uIrJBRHaIyAPpfT7OuSTgS6Bbqru6A6+dLo5UMfcUkW8Cbl8qIitFZLeIPA9IwH3nisiXXnzbReRNESnu3fc6UAH40GtJDhKReK/FkM87p5yIzBCRnSKyRkT6BDz3MBGZKiKveZ/NchFJSO8zSI+IFPOeY5v3WT4oInm8+yqLyNfee9suIm97x0VEnhWRrSKyR0SWZaY1Z7LGkogJlbJASeBfwM3ov7VXvdsVgAPA86d4fBNgFVAaeAp4WUQkiHPfAn4ESgHDOPmLO1BGYrweuBE4CzgDuAdARGoAL3jPX857vTS/+D2TAmMRkWpAPS/ezH5WKc9RGngPeBD9LNYCzQJPAZ704jsPKI9+JjjnunFia/KpNF5iCpDkPb4z8ISIXBxw/1XeOcWBGRmJOQ3PAcWASsBFaGK90bvvUeAzoAT62T7nHb8MaAFU9R57DbAjiNc2wXDO2cUuWb4AiUBr73pL4B8g5hTn1wP+Crg9B+jtXe8JrAm4ryDggLKZORf9Aj4MFAy4/w3gjQy+p7RifDDg9m3Ap971h4EpAfcV8j6D1uk8d0FgD9DUu/048EGQn9U33vXuwPcB5wn6pd87neftCPyU1t+hdzve+yzzoQnnCFAk4P4ngYne9WHAFwH31QAOnOKzdUDlVMfyep9ZjYBjtwBzvOuvAeOAuFSPuxhYDZwP5PH7/0K0XawlYkJlm3PuYMoNESkoIi95XRR7gLlAcUl/5M+fKVecc/u9q4UzeW45YGfAMYCN6QWcwRj/DLi+PyCmcoHP7Zzbxyl+DXsxvQN091pNN6BfksF8VilSx+ACb4vI2SIyRUQ2ec/7BtpiyYiUzzI54NgGIDbgdurPJkYyVw8rDeT3njet1xiEJsYfve6yXgDOuS/RVs8YYKuIjBORopl4XZMFlkRMqKReHnogUA1o4pwrinY/QECffQhsBkqKSMGAY+VPcX5WYtwc+Nzea5Y6zWMmoV0vlwJFgA+zGEfqGIQT3+8T6N9Lbe95/53qOU+1pPcf6GdZJOBYBWDTaWLKjO3AIbQb76TXcM796Zzr45wrh7ZQxoo3wss5N9o51xBtAVUF7s3GuMwpWBIxOaUI2re/S0RKAkND/YLOuQ3AQmCYiJwhIhcAV4YoxmlAexG5UETOAIZz+v9f84BdaBfNFOfcP1mMYyZQU0Su9loAd6LdeimKAHuB3SISy8lftFvQWsRJnHMbgfnAkyISIyJ1gJvQ1kywzvCeK0ZEYrxjU4HHRaSIiPwLGJDyGiLSJWCAwV9o0jsqIo1EpImI5Af2AQeBo1mIy2SCJRGTU0YCBdBfm98Dn+bQ694AXIB2LT0GvA38nc65IwkyRufccqAfWhjfjH7JJZ3mMQ7twvqX92eW4nDObQe6AP9B328V4NuAUx4BGgC70YTzXqqneBJ4UER2icg9abxEV7RO8gfwPjDUOfdFRmJLx3I0WaZcbgTuQBPBOuAb9PN8xTu/EfCDiOxFC/f9nXPrgKLAePQz34C+9/9lIS6TCeIVpoyJCt6w0JXOuZC3hIyJBtYSMbma19VxrojkEZHLgQ7AdJ/DMibXsJnEJrcri3bblEK7l/o6537yNyRjcg/rzjLGGBM0684yxhgTtKjrzipdurSLj4/3OwxjjIkoixYt2u6cK5P6eNQlkfj4eBYuXOh3GMYYE1FEZENax607yxhjTNAsiRhjjAmaJRFjjDFBi7qaiDEmZx06dIikpCQOHjx4+pON72JiYoiLiyN//vwZOt+SiDEmpJKSkihSpAjx8fGkv6+YCQfOOXbs2EFSUhIVK6bevTlt1p1ljAmpgwcPUqpUKUsgEUBEKFWqVKZajZZEjDEhZwkkcmT278qSSAYcPQqvvgrvv+93JMYYE14siWSAczBmDPTrB3v2+B2NMSYzduzYQb169ahXrx5ly5YlNjb22O1//vnnlI9duHAhd95552lfo2nTptkS65w5c2jfvn22PFdOscJ6BuTNC2PHwvnnwyOPwNNP+x2RMSajSpUqxZIlSwAYNmwYhQsX5p57ju+5dfjwYfLlS/urMCEhgYSEhNO+xvz587Ml1khkLZEMatwY+vSBUaPgl1/8jsYYkxU9e/bk1ltvpUmTJgwaNIgff/yRCy64gPr169O0aVNWrVoFnNgyGDZsGL169aJly5ZUqlSJ0aNHH3u+woULHzu/ZcuWdO7cmerVq3PDDTeQslL6xx9/TPXq1WnYsCF33nnnaVscO3fupGPHjtSpU4fzzz+fpUuXAvD1118fa0nVr1+f5ORkNm/eTIsWLahXrx61atVi3rx52f6ZpcdaIpnwxBMwbZp2a82ZA1YrNCZz7roLvEZBtqlXD0aOzPzjkpKSmD9/Pnnz5mXPnj3MmzePfPny8cUXXzBkyBDefffdkx6zcuVKvvrqK5KTk6lWrRp9+/Y9aT7FTz/9xPLlyylXrhzNmjXj22+/JSEhgVtuuYW5c+dSsWJFunbtetr4hg4dSv369Zk+fTpffvkl3bt3Z8mSJYwYMYIxY8bQrFkz9u7dS0xMDOPGjaNNmzY88MADHDlyhP3792f+AwmStUQyoVQp+M9/YO5ceOstv6MxxmRFly5dyJs3LwC7d++mS5cu1KpVi7vvvpvly5en+Zh27dpx5plnUrp0ac466yy2bNly0jmNGzcmLi6OPHnyUK9ePRITE1m5ciWVKlU6NvciI0nkm2++oVu3bgBcfPHF7Nixgz179tCsWTMGDBjA6NGj2bVrF/ny5aNRo0a8+uqrDBs2jGXLllGkSJFgP5ZMs5ZIJt10E0yYAPfcA+3bQ7FifkdkTOQIpsUQKoUKFTp2/aGHHqJVq1a8//77JCYm0rJlyzQfc+aZZx67njdvXg4fPhzUOVkxePBg2rVrx8cff0yzZs2YNWsWLVq0YO7cucycOZOePXsyYMAAunfvnq2vmx5riWRSnjw6UmvLFhg2zO9ojDHZYffu3cTGxgIwceLEbH/+atWqsW7dOhITEwF4++23T/uY5s2b8+abbwJaayldujRFixZl7dq11K5dm/vuu49GjRqxcuVKNmzYwNlnn02fPn3o3bs3ixcvzvb3kB5LIkFISIBbboHnngOv1mWMiWCDBg3i/vvvp379+tnecgAoUKAAY8eO5fLLL6dhw4YUKVKEYqfpxhg2bBiLFi2iTp06DB48mEmTJgEwcuRIatWqRZ06dcifPz9t27Zlzpw51K1bl/r16/P222/Tv3//bH8P6Ym6PdYTEhJcdmxKtXMnVK0K1avDvHlWZDcmPb/++ivnnXee32H4bu/evRQuXBjnHP369aNKlSrcfffdfoeVprT+zkRkkXPupPHO1hIJUsmS8N//wrffwuuv+x2NMSbcjR8/nnr16lGzZk12797NLbfc4ndI2cJaIllw9Cg0awbr1sGqVVC8eLY8rTG5irVEIo+1RHJISpF9+3Z4+GG/ozHGmJxnSSSLGjSAvn01mWT3JCpjjAl3lkSywaOP6kTEfv20i8sYY6KFJZFsUKIEPPUUzJ8P3ig8Y4yJCpZEskn37tC0KQwaBH/95Xc0xpgUrVq1YtasWSccGzlyJH379k33MS1btiRlAM4VV1zBrl27Tjpn2LBhjBgx4pSvPX36dFasWHHs9sMPP8wXX3yRiejTFk5LxlsSySYpRfadO+HBB/2OxhiTomvXrkyZMuWEY1OmTMnQ+lWgq+8WD3LoZeokMnz4cFq3bh3Uc4UrSyLZqF49uP12eOEFWLTI72iMMQCdO3dm5syZxzagSkxM5I8//qB58+b07duXhIQEatasydChQ9N8fHx8PNu3bwfg8ccfp2rVqlx44YXHlosHnQPSqFEj6taty//93/+xf/9+5s+fz4wZM7j33nupV68ea9eupWfPnkybNg2A2bNnU79+fWrXrk2vXr34+++/j73e0KFDadCgAbVr12blypWnfH9+LxlvCzBms0cegbff1iL7/PnaQjHGeHxYC75kyZI0btyYTz75hA4dOjBlyhSuueYaRITHH3+ckiVLcuTIES655BKWLl1KnTp10nyeRYsWMWXKFJYsWcLhw4dp0KABDRs2BODqq6+mT58+ADz44IO8/PLL3HHHHVx11VW0b9+ezp07n/BcBw8epGfPnsyePZuqVavSvXt3XnjhBe666y4ASpcuzeLFixk7diwjRoxgwoQJ6b4/v5eMt6+4bFa8OPzvf/DDD7ovuzHGf4FdWoFdWVOnTqVBgwbUr1+f5cuXn9D1lNq8efPo1KkTBQsWpGjRolx11VXH7vvll19o3rw5tWvX5s0330x3KfkUq1atomLFilStWhWAHj16MHfu3GP3X3311QA0bNjw2KKN6fF7yXhriYTAv/8N48bBffdBp066RIoxBt/Wgu/QoQN33303ixcvZv/+/TRs2JD169czYsQIFixYQIkSJejZsycHDx4M6vl79uzJ9OnTqVu3LhMnTmTOnDlZijdlOfmsLCWfU0vGW0skBES0yL5rFwwZ4nc0xpjChQvTqlUrevXqdawVsmfPHgoVKkSxYsXYsmULn3zyySmfo0WLFkyfPp0DBw6QnJzMhx9+eOy+5ORkzjnnHA4dOnRs+XaAIkWKkJycfNJzVatWjcTERNasWQPA66+/zkUXXRTUe/N7yfiQJREReUVEtorISTuSi8hAEXEiUtq7LSIyWkTWiMhSEWkQcG4PEfnNu/QION5QRJZ5jxktEl7r6NapA3fcoS2SBQv8jsYY07VrV37++edjSSRl6fTq1atz/fXX06xZs1M+vkGDBlx77bXUrVuXtm3b0qhRo2P3PfroozRp0oRmzZpRvXr1Y8evu+46/ve//1G/fn3Wrl177HhMTAyvvvoqXbp0oXbt2uTJk4dbb701qPfl95LxIVuAUURaAHuB15xztQKOlwcmANWBhs657SJyBXAHcAXQBBjlnGsiIiWBhUAC4IBF3mP+EpEfgTuBH4CPgdHOuVP/lCB7F2A8nd27dan4uDj4/nvwduI0JqrYAoyRJywWYHTOzQV2pnHXs8AgNCmk6IAmG+ec+x4oLiLnAG2Az51zO51zfwGfA5d79xV1zn3vNAu+BnQM1XsJVrFiMGIELFwIL7/sdzTGGJP9crQmIiIdgE3OuZ9T3RULbAy4neQdO9XxpDSOp/e6N4vIQhFZuG3btiy8g8y7/nq46CK4/35d7dcYY3KTHEsiIlIQGALk+KLpzrlxzrkE51xCmTJlcvS1U4rsu3dbkd1Er2jbtyiSZfbvKidbIucCFYGfRSQRiAMWi0hZYBNQPuDcOO/YqY7HpXE8LNWsqXOsJkzQ+SPGRJOYmBh27NhhiSQCOOfYsWMHMTExGX5MSHc2FJF44KPAwnrAfYlAgldYbwfczvHC+mjnXGOvsL4ISBmttRgtrO9Mo7D+nHPu49PFlJOF9UDJyVpkP+ccTSRWZDfR4tChQyQlJQU9B8PkrJiYGOLi4sifP/8Jx9MrrIdssqGITAZaAqVFJAkY6pxLr7z8MZpA1gD7gRsBvGTxKJAySHa4cy6lWH8bMBEoAHziXcJWkSLw9NPQtasO+z3FAqLG5Cr58+enYsWKfodhQsT2WM9BzsEll8BPP8Hq1ZDD5RljjAma7bEeBkTg+edh714YPNjvaIwxJussieSwGjVgwAB45RX47ju/ozHGmKyxJOKDhx6C2Fi47TY4csTvaIwxJniWRHxQuDA8+6xuq/Dii35HY4wxwbMk4pPOnaF1a3jgAdi61e9ojDEmOJZEfCICzz0H+/fDoEF+R2OMMcGxJOKj6tVh4ECYNAm++cbvaIwxJvMsifjswQehfHndkz3IDcyMMcY3lkR8VqiQFtmXLoWxY/2OxhhjMseSSBi4+mpo00aH/v75p9/RGGNMxlkSCQMpRfaDB63IboyJLJZEwkSVKnDvvfD66zB3rt/RGGNMxlgSCSNDhkCFClpkP3TI72iMMeb0LImEkYIFYdQo+OUXXajRGGPCnSWRMNOhA7RtC0OHwh9/+B2NMcacmiWRMCMCo0fD339rjcQYY8KZJZEwVLky3HcfvPUWzJnjdzTGGJM+SyJh6v77IT7eiuzGmPBmSSRMFSig3VorVuifxhgTjiyJhLErr4T27WHYMNi0ye9ojDHmZJZEwtyoUdqdNXCg35EYY8zJLImEuUqVtD7y9tswe7bf0RhjzIksiUSAQYM0mdx+O/zzj9/RGGPMcZZEIkBKkX3lShg50u9ojDHmOEsiEaJdO53N/sgjsHGj39EYY4yyJBJBUlohV1xh+44YY8KDJZEIEh8PM2bAunVw0UWQlOR3RMaYaGdJJMJccgl89pm2RJo314RijDF+sSQSgZo10+G+e/ZoIlm50u+IjDHRKmRJREReEZGtIvJLwLH/ichKEVkqIu+LSPGA++4XkTUiskpE2gQcv9w7tkZEBgccrygiP3jH3xaRM0L1XsJRQoIuznjkCLRoAUuX+h2RMSYahbIlMhG4PNWxz4Fazrk6wGrgfgARqQFcB9T0HjNWRPKKSF5gDNAWqAF09c4F+C/wrHOuMvAXcFMI30tYql0bvv4azjgDWraEBQv8jsgYE21ClkScc3OBnamOfeacO+zd/B6I8653AKY45/52zq0H1gCNvcsa59w659w/wBSgg4gIcDEwzXv8JKBjqN5LOKtWDebNg+LFtV7yzTd+R2SMiSZ+1kR6AZ9412OBwNkPSd6x9I6XAnYFJKSU41GpYkWYOxfOOQfatIEvvvA7ImNMtPAliYjIA8Bh4M0cer2bRWShiCzctm1bTrxkjouL00Ry7rm68u9HH/kdkTEmGuR4EhGRnkB74AbnnPMObwLKB5wW5x1L7/gOoLiI5Et1PE3OuXHOuQTnXEKZMmWy5X2Eo7PPhq++0lpJp07wzjt+R2SMye1yNImIyOXAIOAq59z+gLtmANeJyJkiUhGoAvwILACqeCOxzkCL7zO85PMV0Nl7fA/gg5x6H+GsVCntzmrSBK67Dl57ze+IjDG5WSiH+E4GvgOqiUiSiNwEPA8UAT4XkSUi8iKAc245MBVYAXwK9HPOHfFqHrcDs4BfganeuQD3AQNEZA1aI3k5VO8l0hQrBrNmQatW0KMHvPSS3xEZY3IrOd6jFB0SEhLcwoUL/Q4jRxw8CJ07w8yZ8MwzcPfdfkdkjIlUIrLIOZeQ+rjNWM/FYmLgvfc0kQwYAI8/7ndExpjcJt/pTzGR7IwzYPJk3ZPkwQdh3z5NJiJ+R2aMyQ0siUSBfPlg4kQoWBCefFITyciRlkiMMVlnSSRK5MkDL7ygieTZZ2H/fnjxRcib1+/IjDGRzJJIFBGBp5+GQoXgscc0kUyapC0VY4wJhn19RBkRePRRbZEMGaIjuCZP1tqJMcZklo3OilL33691kffeg44d4cABvyMyxkQiSyJRrH9/GDcOPv0U2rWDvXv9jsgYE2ksiUS5Pn10aZS5c3UF4N27/Y7IGBNJLIkY/v1vmDpVN7W6+GLYvt3viIwxkcKSiAHg6qth+nRYsUJ3SfzzT78jMsZEAksiGeWcXnKxK67QdbYSE3Xf9o0bT/sQY0yUsySSEYcOwY036nTvXO7ii+Gzz2DLFmjeHNat8zsiY0w4sySSEfnywT//6OJTH3/sdzQh17QpfPklJCdrIlm50u+IjDHhypJIRojAhAlQty5cfz2sXu13RCHXsCHMmQNHjmjX1tKlfkdkjAlHlkQyqmBBeP99bZV07Ah79vgdUcjVrq1Df888U4vtCxb4HZExJtxYEsmM+HgdC7t6tW4ZePSo3xGFXNWqMG8eFC8Ol1wC33zjd0TGmHBiSSSzLr4YRozQ8bCPPeZ3NDkiPl4TSblycNlluoe7McaAJZHg9O+vM/SGDoUZM/yOJkfExsLXX0PlytC+PXz0kd8RGWPCgSWRYIjoolMNGmgyiZLhS2efrcX2OnWgUyd47rlcP3XGGHMalkSCVaCAFtpjYrTQHiWLTpUsqd1ZbdrAnXdChw62TIox0cySSFZUqADvvANr12qLJAoK7QBFi8KHH8KoUTBrlo58/uorv6MyxvghQ0lERAqJSB7velURuUpE8oc2tAhx0UW63+xHH8Ejj/gdTY4R0ZbIDz9AkSI6cuvBB3VyvzEmemS0JTIXiBGRWOAzoBswMVRBRZx+/aBnTxg+XLu4oki9erBoka4K8/jjmlMTE/2OyhiTUzKaRMQ5tx+4GhjrnOsC1AxdWBFGBF54ARo1gu7ddSncKFKoELz8sm6zu3y5JpapU/2OyhiTEzKcRETkAuAGYKZ3LG9oQopQMTG612zBglpt3rXL74hy3HXXwZIlcN55cO21uuHVvn1+R2WMCaWMJpG7gPuB951zy0WkEmCl1NTi4uDdd7U/5/rrdeGpKFOxoi6VMmSItk4SEuDnn/2OyhgTKhlKIs65r51zVznn/usV2Lc75+4McWyR6cILdQLFJ5/Aww/7HY0v8ufX+sjnn+vI58aNbU6JMblVRkdnvSUiRUWkEPALsEJE7g1taBHsllugd2944gmYNs3vaHxzySXaCrn0UptTYkxuldHurBrOuT1AR+AToCI6QsukRQSefx7OP19HbS1b5ndEvilTxuaUGJObZTSJ5PfmhXQEZjjnDgGn7JwQkVdEZKuI/BJwrKSIfC4iv3l/lvCOi4iMFpE1IrJURBoEPKaHd/5vItIj4HhDEVnmPWa0iEgm3nfonXmm1keKFNEZ7Tt3+h2Rb2xOiTG5V0aTyEtAIlAImCsi/wJOt6HGRODyVMcGA7Odc1WA2d5tgLZAFe9yM/ACaNIBhgJNgMbA0JTE453TJ+BxqV/Lf+XK6YitjRuha9eoLLQHsjklxuQ+GS2sj3bOxTrnrnBqA9DqNI+ZC6T++d0BmORdn4S2bFKOv+Y99/dAcRE5B2gDfO6c2+mc+wv4HLjcu6+oc+5755wDXgt4rvBywQUwdqxuXD5kiN/R+M7mlBiTu2S0sF5MRJ4RkYXe5Wm0VZJZZzvnNnvX/wTO9q7HAhsDzkvyjp3qeFIax9OL/+aU2Ldt2xZE2FnUuzfceis89RRMmZLzrx+GbE6JMblDRruzXgGSgWu8yx7g1ay8sNeCyJFBn865cc65BOdcQpkyZXLiJU82ahQ0awa9etnECY/NKTEm8mU0iZzrnBvqnFvnXR4BKgXxelu8rii8P7d6xzcB5QPOi/OOnep4XBrHw9cZZ+hw35IltdC+Y4ffEYUFm1NiTGTLaBI5ICIXptwQkWbAgSBebwaQMsKqB/BBwPHu3iit84HdXrfXLOAyESnhFdQvA2Z59+0RkfO9UVndA54rfJUtq4X2P/7QPpzDh/2OKGzYnBJjIlNGk8itwBgRSRSRROB54JZTPUBEJgPfAdVEJElEbgL+A1wqIr8Brb3bAB8D64A1wHjgNgDn3E7gUWCBdxnuHcM7Z4L3mLXo/JXw17gxvPgizJ4N993ndzRhJfWckjp14Msv/Y7KGHMq4jLRbyAiRQGcc3tE5C7n3MhQBRYqCQkJbuHChX6HAXfcoRMS33gDbrjB72jCzpIlWnxfvRruvx+GDdOuL2OMP0RkkXMuIfXxTO1s6Jzb481cBxiQLZFFq2eegRYtdOTW4sV+RxN2AueUPPGEflTr1/sdlTEmtaxsjxteM8QjTf78urVumTLQqRP4MfQ4zAXOKVmxQhPL22/7HZUxJlBWkoiNn8mqs87SnRC3boVrrrF1QNKRMqekRg293ru3zSkxJlycMomISLKI7EnjkgyUy6EYc7eGDWHcOJgzB+65x+9owlbgnJJXXtGPbckSv6MyxpwyiTjnijjniqZxKeKcy5dTQeZ63brBXXfB6NEwadJpT49WgXNK9uyBJk10JFeUL0kWXo4e1fHavXrB/v1+R2NyQFa6s0x2+t//oFUr3YtkwQK/owlrgXNK7rpLt7b/+mu/ozKADl3/8kt49VVdocFW2Mz1LImEi3z5tGpctixcfTVs2eJ3RGEtZU7J5Mk6KbFlS+jcGdat8zuyKDduHJQqpdsgrF+va9nYZJ9czZJIOClTRgvtO3ZAly7wzz9+RxTWRLTQvmoVPPqo7kh83nkweLB2d5kctmULTJ8OPXroD6Eff9TBI5deCs8+a2vZ5FKWRMJN/fo6rnXePBhgU3EyokAB3eRq9WrdtuW//4UqVWDCBKuX5KhJk3Qpnz599HbVqroTWYcO+m+5Wzerk+RClkTCUdeuOlJrzBgdimQyJDYWJk7UH8BVquh3WUKCDnwzIeYcjB8PzZtD9erHjxcpoguPPvoovPUWXHghbNjgX5wm21kSCVdPPgmtW0PfvvprzmRYo0bakJsyRXclbtUK/u//YO1avyPLxebMgTVr4OabT74vTx5tKn74of4lNGxodZJcxJJIuMqXT78FY2O1f3nz5tM/xhwjogslr1wJjz2mCzrWqKFrXlq9JATGjYMSJTRbp6ddOx15eNZZcNllVifJJSyJhLNSpbRQuWuXDj2yQnumFSgADzyg9ZLrr9fNJatU0Z4Xq5dkk+3bdYuDbt30Az+VqlXh++/hyiuP10kOBLOrhAkXlkTCXZ06OuZ+/nzdaMMEpVw5/RgXLNDvsZtvhgYN4Kuv/I4sF3jtNf2Bk1JQP52iRXUI8PDhWidp1szqJBHMkkgkuOYaHbf60kvabWCClpCgy6dMnao7KV58sa5/uWaN35FFKOf032TTplCrVsYflycPPPQQzJihdZKEBMvoEcqSSKR47DG4/HK4/Xb49FO/o4loIjoN59dfjy+jUqMGDBqkicVkwrx5OlEno62Q1Nq31+ZhmTI6n2TkSKuTRBhLIpEib15t+lerBm3b6jee1UiypEABXdDxt9+0a37ECK2XvPSS1UsybPx4KFZMW8vBCqyT3H03dO9udZIIYkkkkpQoocN9b71V19q64AL9FWiy5JxzdH7nggU6xeHWW3XOp41CPY2dO3VPnH//GwoWzNpzpdRJHnlEd/u0OknEsCQSaQoWhBde0OVREhO1OjxhgnUBZIOGDXUhx3fegeRkXeixY0dtqZg0vP46/P138F1ZqeXJAw8/fHw+idVJIoIlkUjVsSMsXQrnn6//ibt00V+GJktEdDT1r7/qfM/Zs6FmTV1AYNcuv6MLIykF9caNoW7d7H3u9u112YHSpbVOMmqU/UgKY5ZEIllsrFaFn3oKPvhA/zPbGh/ZIiZGB8T99pt20T/zjNZLXnxRl4eKet99p3sWpzVDPTtUq6Zdt+3b63r/PXpYnSRMWRKJdHnywL33amGyQAEds/rAA7bVbjYpW1Z7Cxct0hFcfftqveSLL/yOzGfjxkHhwrosQKgULaqTGB95RLvOLrwQfv89dK9ngmJJJLdo2BAWL9Yd5Z54Qv/D2eSHbFO/vjbypk3T/d0vvRSuuipK6yW7dulEmxtu0EQSSil1khkz9N9zw4bW2g4zlkRyk8KF9WfzO+/oOh/16+vy3NafnC1EdGmoFSvgP//R77KaNWHgwCirl7z5pnYthaorKy1XXnm8TtK6tdVJwoglkdyoc2ctujdsCD176tLyUfUtF1oxMbqQ4+rV2lX/7LNQvrz+MP/gAzh40O8IQ8g5nUjTsKGODMxJKXWSdu2sThJGLInkVuXL69Cixx/XPpi6deGbb/yOKlcpW1bn2i1erHl61iwdNHfWWTp1YsYMHQGbq/z4Iyxbln3DejOraFEd3p5SJ2ne3OokPrMkkpvlzatTsr/9VpeWv+giGDrUhhdls3r1tM68ebMmkmuu0a16O3TQhNK9O3z0US5JKOPHQ6FCmjX9Elgn+e0323nMZ5ZEokGTJrBkia7tMXw4tGgB69f7HVWukz+/bpMxYQL8+acucda5s86du/JKOPts7V38+OMIXbFmzx6YPFkTSNGifkdzvE5SsqTWSUaPtjqJDyyJRIsiRXTv2MmTYfly/fn81lt+R5Vr5c8Pbdrocipbtmji6NRJt4dp104TSq9emmgiZjT2W2/pHul+dWWlJbBO0r+/Zmmrk+QocVGWuRMSEtzChQv9DsNfiYnaaf/tt/rnmDHh8csyCvz9t84xmTpVE8qePbok2tVXazdYq1aagMJSw4a6MuVPP+lQtXBy9Kju4z5smMb53ntQoYLfUeUqIrLIOZeQ+rgvLRERuVtElovILyIyWURiRKSiiPwgImtE5G0ROcM790zv9hrv/viA57nfO75KRNr48V4iUny89iEPG6a/LuvV08mKJuTOPFN/NE+aBFu3ard+u3aaVNq00cUg+/TRhQjCqnS1aJGOILj55vBLIKB1kqFDdXjc6tVaJ/n6a7+jigo53hIRkVjgG6CGc+6AiEwFPgauAN5zzk0RkReBn51zL4jIbUAd59ytInId0Mk5d62I1AAmA42BcsAXQFXn3CkX8baWSCrffqtjU5OSNKncf78W5E2OOnhQi/JTp2pi2btXp0SktFAuukjHRvjmllt0NNTmzbr0ezhbuVKHya1ZoxtllS+vrZLy5U+8xMbCGWf4HW3ESK8l4lcS+R6oC+wBpgPPAW8CZZ1zh0XkAmCYc66NiMzyrn8nIvmAP4EywGAA59yT3vMeO+9Ur29JJA27d+t6HpMn65DJN96wrgAfHTigtZKpU7Uov2+f7tn0f/+nCaVFixzO83v3ahOpc2fdYzgS7N6tKzesWAEbN+ow4L/+OvEcER2nnTq5BCads8+2H1We9JJIjv+2cc5tEpERwO/AAeAzYBGwyzmX0oBPAmK967HARu+xh0VkN1DKOx7YBxP4mBOIyM3AzQAV7MvxZMWK6Szktm2hXz+dU/LSS1nbaMgErUABLcJ36qR17E8+0YTy2mu6AOTZZx9PKBdemAPfcVOmaCLJyRnqWVWsGPz3vyce27dPE0rg5fff9c/lyzVz79t34mPy5dMWS1oJJuVSqlR4dvHlED9aIiWAd4FrgV3AO8A0tBVR2TunPPCJc66WiPwCXO6cS/LuWws0AYYB3zvn3vCOv+w9ZtqpXt9aIqexbh1cf72OeLnxRh02Ger1kUyG7Nuno7ymToWZM7XFUrasNhCuuUb3ccoTiipn48aazZYty91fls7pyg6BySWtS+rhdAUKQFxc2l1mKUmnSBFf3lJ2CpuWCNAaWO+c2wYgIu8BzYDiIpLPa43EAZu88zcB5YEkrzurGLAj4HiKwMeYYFWqpPtmDx+us92/+UaL7wkn/dsxOaxQId02pksXbRjMnKkJZcIEeP557XG69FLdnbFaNb1UrqzF/KAtWaJbPo4albsTCOj7K1FCL3XqpH3O0aM6IiKt5PL77zoiYvNmPS9QyZI6oKVixRP/TLkUKhTStxZKfrREmgCvAI3Q7qyJwEKgBfBuQGF9qXNurIj0A2oHFNavds5dIyI1gbc4XlifDVSxwno2mjtXhwBv3qzDJ++91/qHw1By8vGE8sMP8Mcfx+/Lk0e/r6pVOzG5VK+us+lPmxf69YNXXoFNm/SL0JzeoUP6fyYluWzYoJf163V4fWLiyQuslSlzYmIJTDb/+pcu2OazsCmse8E8gnZnHQZ+Anqj9YwpQEnv2L+dc3+LSAzwOlAf2Alc55xb5z3PA0Av73nucs59crrXtiSSSX/9pSNz3nlHJzG89po23U3YSk7WUa4rV8KqVXpZuVKPBX53FSuWdnI51nrZtw/KldM1719/3bf3k+s4pzNQExOPJ5bABLNhw8lLGpQtm3YrpmJF7S7LgVFmYZVE/GRJJAjO6Wz3O+7Qf6wTJujYUxNRjh7VH8YpSSUwwWwK6AjOk0e/n24v9Cp3L+vFBwPnUvzK5lSrpkX93N6r5bujR7UlE5hYApPN77/rpM8UIlr8T6sVEx+vP/qyYQarJRGPJZEs+O03LbovXKgz4kaMsJnuucTevSe3Xu7/sClnHviL89wKQDNH0aLpt17CoMclOhw+rH2WabVi1q/XOV+BNZm8eTWRxMfrJKQg/89aEvFYEsmif/7RFVSfekpnww0bpgklbNfqMEFZtgzq1OHoiKdJ6jIgzdZLUtLx00X0OyoluVx4IVx+eUTXiyPXoUPa5EzdiklK0u0hghzCZ0nEY0kkmyxaBPfco8unVKumSeXKK62vI7e4806dK7Rpk/5YSMO+fSe3XlIu+/dry+TSS3Xy+JVXau3YRC5LIh5LItnIOd0oY9Ag/Sa56CLt4rLhwJHtwAEtqLdtG9RKz4cP62o677+vi0xu2KA/fps104TSsaOOJDeRJawWYDS5hIj+xFy2DMaO1SUmGjXSYcEbNvgdnQnWtGk66S7IGeop+5+NHKk9KT/9BA89pCsWDxwI556riyIMHar3Rdnv2FzHWiIm++zZo0tNPPOMfjPcdZcu6BjuC/aZEzVvrkNQV63K9u7J9et1od3339d5rEeP6gjVlBZK8+Y+LzRp0mUtERN6RYvqLPfVq+Haa7VOcu65Op06YnZeinK//qrf7n36hKS+VbGi/rb4+mvd/fGVV45vL3zxxcd3f5w+XesqJvxZEjHZr3x53TBj4ULtt7jjDqhZU78ZoqzlG3HGj9eRdj16hPylypTR5dk++AC2b9d9pNq311GonTppPb9jR52itH17yMMxQbIkYkKnQQPdxu+jj7SPolMn7Sz/8Ue/IzNpOXhQk3/HjromSg4qVEj/eUyapD1ps2dD7966D9aNN2oLpWVLrbMkJuZoaOY0LImY0BLRrfuWLtV1zFetgiZNdNKifRuEl/ffh507fV/yPX9+7doaPVrHZyxaBA88oKHdfbd2idWvD488Aj//bI1bv1lh3eSs5GStlTz9tC7d0L8/DBkCxYv7HZlp1UqX1PjttxCtKZ91a9Zo99f06TqM2Dmd5JhSmG/WzArzoWKFdRMeihTRFYFXr9bWyIgRWnwfPfrkRedMzlm9WieO9u4dtgkEdHmVgQN1t4I//9Rl3GrVghde0O6uc86BXr20rnLggN/RRofw/ddicre4ON1qdfFi7Zvo31+L7+++a/0TfpgwQX/C33ij35Fk2FlnwU036RbC27fr9JY2bbRA36GDFub79IFffvE70tzNkojxV716upHPxx/r+uOdO+tkgR9+8Duy6PH335rQr7pKlxyPQIUL65bBb7wB27bpP6nrr9ddn2vX1uVXZs48ea8ok3WWRIz/RHSJjSVLdMLAmjVw/vlw3XW6Xa8JrZQxtn36+B1JtsifH1q31tHKGzfCk0/q9Jf27eG883Rxhb17/Y4y97AkYsJHvnz6RbZmja4U/OGHuizswIG6OZYJjfHjdfe8Sy/1O5JsV6oUDB6sM+XfeksXT+jXT6cyDRqk4whM1lgSMeGncGEdv7l6NXTrBs8+q8X3Z5/VrheTfdau1bk8vXvn6q2P8+eHrl21l3T+fLjsMl2dp1IlXVzhu++sFBcsSyImfMXGwssvazdXo0YwYADUqKEVVPsfnz0mTNDRWBFUUM8KEbjgAnj7be0pHTAAPvsMmjbVHtTJk22FnsyyJGLCX506MGsWfPopFCwIXbrohIDvvvM7ssh26JAW1Nu314QdZSpU0ClLGzfCmDG6cPH11+tkxiefhB07/I4wMlgSMZGjTRttlUyYoLPdmzbVITnWFxGcDz/UNUZ8nqHut8KF4bbbtPj+0UdafB8yROsmt96qx036LImYyJI3r04O+O03rZt88YUmkwYNNLnY0q8ZN26czte5/HK/IwkLefLoCj2ff65b5Nxwgy7+WKOGfkSffmq/VdJiScREpkKFdATXpk26JteRIzqyKzZWF1havdrvCMNbYqIWA266KVcX1INVq9bxIcKPPaZLv7Vtq/NhX3rJfqsEsiRiIlvhwnDLLboS37x5+pNxzBjd9/2yy3QOxJEjfkcZfl5+WavMvXr5HUlYK1NGF39MTITXX4cCBbSLq3x53W8tKcnvCP1nScTkDiJw4YU6vOb333V9rl9/Pb6h9xNPwNatfkcZHg4f1iTStq1Wl81pnXGG7vq8cKH+VmnVSovyFStqMT6adzewJGJyn7Jl4cEHdYbZe+9BlSr6czIuTju658+P7s7tmTNh8+ZcM0M9J6X8Vpk2TefE3nmnfpxNmmhpbupUzdHRxJKIyb1SNsL64gttlfTtq8NvmjXTQvz48bBvn99R5rzx43W523bt/I4kolWsqDsaJCXpItRbt+rExUqVtJUSLYssWBIx0aF6dRg1Cv74QyujR4/q0NbYWN30O1oK8b//Dp98ogV123gjWxQpojtAr1qlJbjKleG++7Th26+f/n7JzQ1f25TKRCfntFtr7Fh45x2deHfppTphoH373PsFO2wYDB+u07Xj4/2OJtf6+Wf9zfLmm7pNTunSULeuzptNudSoATExfkeaceltSmVJxJgtW3SOyUsv6ZjO8uV1xFfv3rq5d25x5Igmjpo1ddKDCbktW/Q3ypIlOkz4l1+Ob5aVN68OIkxJKilJJjZWay/hxpKIx5KISdfhw1ozGTNG6yj58+v+Jv36adU0HP9nZ8bMmdrKevdduPpqv6OJSkeOaEF+6dLjl59/1r3kU5QocWJSqVNH837Bgv7FDWGWRESkODABqAU4oBewCngbiAcSgWucc3+JiACjgCuA/UBP59xi73l6AA96T/uYc27S6V7bkojJkFWrdM/ViRNh9279H33bbTq6q1Ahv6MLTocOuoztxo2aIE3Y2L1bZ8mnJJWlS/V2yriPPHl0kGHqVkuFCjn32ybcksgkYJ5zboKInAEUBIYAO51z/xGRwUAJ59x9InIFcAeaRJoAo5xzTUSkJLAQSEAT0SKgoXPulGMiLImYTNm3TzeiGDNG/3cXKwY9e+pIr2rV/I4u4zZt0j1D7r1XVxc0Ye/oUS1dpW61BO7TVqzYiXWWOnV0J8dQ/M4JmyQiIsWAJUAlF/DiIrIKaOmc2ywi5wBznHPVROQl7/rkwPNSLs65W7zjJ5yXHksiJijO6UKPY8YcL8S3bq2tkyuvDP9C/GOPwUMPaV/Kuef6HY3JguRkra2ktFhSLsnJer+I/hWnbrXEx2uLJljhlETqAeOAFUBdtAXRH9jknCvunSPAX8654iLyEfAf59w33n2zgfvQJBLjnHvMO/4QcMA5NyKN17wZuBmgQoUKDTcEdkAak1lbt2oh/sUXtWsoLk6TyW236U/DcHP0qE5eqFxZaz0m13FOl2ZJ3WpZs+b48OLChXWEd4kSwb1GeknEj3ki+YAGwAvOufrAPmBw4AleCyXbsptzbpxzLsE5l1CmTJnseloTrc46S9cKX7cOpk8/vnZ4fLwOn921y+cAU/n8c63cRvmS77mZiE5+7NBBG5zvvKNTn5KTtQw2frz2wAabQE7FjySSBCQ5537wbk9Dk8oWrxsL78+UhY42AeUDHh/nHUvvuDE5I18+/V/72WewaBG0bAlDh2oyGToUdu70O0I1bpyuJNixo9+RmBxWqBA0bqyj1Z96KjSvkeNJxDn3J7BRRFKqkpegXVszgB7esR7AB971GUB3UecDu51zm4FZwGUiUkJESgCXeceMyXkNGsD778NPP2mtZPhwTSYPPODvFnmbN8OMGdCjh64iaEw282vZkzuAN0VkKVAPeAL4D3CpiPwGtPZuA3wMrAPWAOOB2wCcczuBR4EF3mW4d8wY/9Srp6vzpWxA8eSTmkwGD4Zt23I+nokTdf6LLbZoQsQmGxoTSsuXw+OPw5QpuhnFbbfBPffkzEz4o0d1ckGFCvDVV6F/PZOrhVNh3ZjoUbOmzjNZsUJniT/zjFZABwyAP/8M7Wt/+aUW/62gbkLIkogxOaF6dd0a79dfoUsXXTu8YkXo319XFg6FceOgZEldDt+YELEkYkxOqloVJk2ClSuha1edvFipEtx+e/butbp1qw4/7tEjspaKNRHHkogxfqhcGV55RQfzd+umKwife64O5v/996w//6RJOqveCuomxCyJGOOnSpV0JtiaNXDjjbr3eeXKuhR9YmJwz+mcPueFF+pESGNCyJKIMeHgX//SZVTWrtXWw8SJOrKqd+8TV9zLiK+/ht9+s4K6yRGWRIwJJ+XLa51k7Vrt2nrjDa2j3HijJoaMGDcOihfXvVCMCTFLIsaEo7g4HcG1bp1u4D1lio7w6t5d9zpJz/btuulUt246L8WYELMkYkw4K1cOnn0W1q+Hu+7S2fA1aujmWL/+evL5r7+um3pbQd3kEEsixkSCsmXh6ae12D5woA7frVkTrrtON5cALaiPGwcXXKA7ExmTAyyJGBNJzjpLl2NNTIT77tN902vX1gmM48bp/BNrhZgcZGtnGRPJduzQ7q7Ro3XziKJFdQZ8pO4Db8JWemtnhfmensaYUypVSre+HTgQxo7VpVQsgZgcZEnEmNygRAndu8SYHGY1EWOMMUGzJGKMMSZolkSMMcYEzZKIMcaYoFkSMcYYEzRLIsYYY4JmScQYY0zQLIkYY4wJWtQteyIi24ANQT68NLA9G8OJdPZ5HGefxYns8zgut3wW/3LOlUl9MOqSSFaIyMK01o6JVvZ5HGefxYns8zgut38W1p1ljDEmaJZEjDHGBM2SSOaM8zuAMGOfx3H2WZzIPo/jcvVnYTURY4wxQbOWiDHGmKBZEjHGGBM0SyIZICKXi8gqEVkjIoP9jsdPIlJeRL4SkRUislxE+vsdUzgQkbwi8pOIfOR3LH4SkeIiMk1EVorIryJygd8x+UlE7vb+n/wiIpNFJMbvmLKbJZHTEJG8wBigLVAD6CoiNfyNyleHgYHOuRrA+UC/KP88UvQHfvU7iDAwCvjUOVcdqEsUfyYiEgvcCSQ452oBeYHr/I0q+1kSOb3GwBrn3Drn3D/AFKCDzzH5xjm32Tm32LuejH5JxPoblb9EJA5oB0zwOxY/iUgxoAXwMoBz7h/n3C5fg/JfPqCAiOQDCgJ/+BxPtrMkcnqxwMaA20lE+ZdmChGJB+oDP/gcit9GAoOAoz7H4beKwDbgVa9rb4KIFPI7KL845zYBI4Dfgc3AbufcZ/5Glf0siZigiEhh4F3gLufcHr/j8YuItAe2OucW+R1LGMgHNABecM7VB/YBUVtDFJESaK9FRaAcUEhE/u1vVNnPksjpbQLKB9yO845FLRHJjyaQN51z7/kdj8+aAVeJSCLa1XmxiLzhb0i+SQKSnHMpLdNpaFKJVq2B9c65bc65Q8B7QFOfY8p2lkRObwFQRUQqisgZaGFshs8x+UZEBO3z/tU594zf8fjNOXe/cy7OOReP/tv40jmX635tZoRz7k9go4hU8w5dAqzwMSS//Q6cLyIFvf83l5ALBxrk8zuAcOecOywitwOz0NEVrzjnlvsclp+aAd2AZSKyxDs2xDn3sX8hmTByB/Cm94NrHXCjz/H4xjn3g4hMAxajoxp/IhcugWLLnhhjjAmadWcZY4wJmiURY4wxQbMkYowxJmiWRIwxxgTNkogxxpigWRIxJhuIyBERWRJwybaZ2iISLyK/ZNfzGZOdbJ6IMdnjgHOunt9BGJPTrCViTAiJSKKIPCUiy0TkRxGp7B2PF5EvRWSpiMwWkQre8bNF5H0R+dm7pCyTkVdExnt7U3wmIgW88+/09nZZKiJTfHqbJopZEjEmexRI1Z11bcB9u51ztYHn0RV/AZ4DJjnn6gBvAqO946OBr51zddF1p1JWR6gCjHHO1QR2Af/nHR8M1Pee59bQvDVj0mcz1o3JBiKy1zlXOI3jicDFzrl13sKVfzrnSonIduAc59wh7/hm51xpEdkGxDnn/g54jnjgc+dcFe/2fUB+59xjIvIpsBeYDkx3zu0N8Vs15gTWEjEm9Fw61zPj74DrRzhez2yH7rzZAFjgbX5kTI6xJGJM6F0b8Od33vX5HN8q9QZgnnd9NtAXju3bXiy9JxWRPEB559xXwH1AMeCk1pAxoWS/WozJHgUCVjUG3Wc8ZZhvCRFZirYmunrH7kB3ALwX3Q0wZbXb/sA4EbkJbXH0RXfFS0te4A0v0Qgw2rajNTnNaiLGhJBXE0lwzm33OxZjQsG6s4wxxgTNWiLGGGOCZi0RY4wxQbMkYowxJmiWRIwxxgTNkogxxpigWRIxxhgTtP8HWX119uWFskwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8238ea9c-3c95-4fcf-b91e-23dce46def95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-107-ba5a6c8492f4>\u001b[0m(23)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     20 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 23 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(32, 45, 4), dtype=float64, numpy=\n",
      "array([[[ 1.94390468, -2.37813562, -2.40565595,  1.18662857],\n",
      "        [ 2.19773181, -2.37813562, -2.40565595,  1.18662857],\n",
      "        [ 1.94390468, -2.58841917, -2.40565595,  1.18662857],\n",
      "        ...,\n",
      "        [-1.45737889, -0.48558363, -1.00042008,  0.81555045],\n",
      "        [-1.45737889, -0.48558363, -1.00042008,  1.18662857],\n",
      "        [-1.07663819, -0.27530007, -0.85989649,  1.18662857]],\n",
      "\n",
      "       [[ 1.7916084 , -2.37813562, -2.40565595,  1.18662857],\n",
      "        [ 2.32464538, -2.58841917, -2.40565595,  1.18662857],\n",
      "        [ 2.00736147, -2.58841917, -2.26513236,  1.18662857],\n",
      "        ...,\n",
      "        [-1.20355176, -0.48558363, -1.00042008,  0.81555045],\n",
      "        [-1.33046533, -0.27530007, -0.85989649,  1.18662857],\n",
      "        [-1.07663819, -0.27530007, -0.85989649,  0.81555045]],\n",
      "\n",
      "       [[ 1.7916084 , -2.37813562, -2.40565595,  1.18662857],\n",
      "        [ 2.19773181, -2.58841917, -2.40565595,  1.18662857],\n",
      "        [ 2.07081825, -2.58841917, -2.26513236,  0.81555045],\n",
      "        ...,\n",
      "        [-0.94972463, -0.48558363, -1.00042008,  1.18662857],\n",
      "        [-1.20355176, -0.27530007, -1.00042008,  1.18662857],\n",
      "        [-1.07663819, -0.27530007, -0.85989649,  1.18662857]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.49709003, -2.58841917, -2.12460877,  0.48570323],\n",
      "        [ 0.16711476, -2.37813562, -1.98408519,  0.81555045],\n",
      "        [-0.25516129, -2.16785206, -1.8435616 ,  0.81555045],\n",
      "        ...,\n",
      "        [-0.27285227, -0.06501652, -0.7193729 ,  1.18662857],\n",
      "        [-0.22208685, -0.06501652, -0.57884932,  1.18662857],\n",
      "        [-0.17132142,  0.14526703, -0.43832573,  1.18662857]],\n",
      "\n",
      "       [[ 0.37017646, -2.58841917, -1.98408519,  0.48570323],\n",
      "        [-0.16286052, -2.37813562, -1.8435616 ,  0.81555045],\n",
      "        [-0.30131168, -2.16785206, -1.8435616 ,  0.81555045],\n",
      "        ...,\n",
      "        [-0.25593046, -0.06501652, -0.57884932,  1.18662857],\n",
      "        [-0.20516504, -0.06501652, -0.57884932,  1.18662857],\n",
      "        [-0.15439961,  0.14526703, -0.43832573,  1.18662857]],\n",
      "\n",
      "       [[ 0.49709003, -2.58841917, -1.98408519,  0.81555045],\n",
      "        [-0.2090109 , -2.37813562, -1.8435616 ,  0.81555045],\n",
      "        [-0.34746207, -2.16785206, -1.8435616 ,  0.81555045],\n",
      "        ...,\n",
      "        [-0.23900866, -0.06501652, -0.7193729 ,  1.18662857],\n",
      "        [-0.18824323, -0.06501652, -0.57884932,  1.18662857],\n",
      "        [-0.1374778 ,  0.14526703, -0.57884932,  1.18662857]]])>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(32, 2), dtype=float64, numpy=\n",
      "array([[0.35926293, 0.87319391],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.7505864 ],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.7505864 ],\n",
      "       [0.24553271, 0.7505864 ],\n",
      "       [0.24553271, 0.62797888],\n",
      "       [0.13180249, 0.87319391],\n",
      "       [0.13180249, 0.87319391],\n",
      "       [0.13180249, 0.62797888],\n",
      "       [0.24553271, 0.7505864 ],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.62797888],\n",
      "       [0.24553271, 0.23563483],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.23563483],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.23563483],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.50537137],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.35926293, 0.50537137],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.23563483],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.62797888],\n",
      "       [0.24553271, 0.38276385],\n",
      "       [0.24553271, 0.38276385]])>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-ba5a6c8492f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-ba5a6c8492f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "import pdb\n",
    "for x, y in dataset_val.take(1):\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466a9b7-546c-4e47-938b-6917e5dbebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
